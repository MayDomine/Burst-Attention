{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def update(q, k, v, m_i,acc_o, softmax_scale=1.0):\n",
    "    qk = q @ k.transpose(-2, -1)*softmax_scale\n",
    "    m_ij = torch.maximum(torch.max(qk, dim=-1, keepdim=True)[0], m_i)\n",
    "    p = torch.exp(qk - m_ij)\n",
    "    l_ij = torch.sum(p, dim=-1, keepdim=True)\n",
    "    acc_o_scale = torch.exp(m_i-m_ij)\n",
    "    acc_o = p @ v + acc_o_scale * acc_o\n",
    "    return m_ij, l_ij, acc_o_scale, acc_o\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def flash_attn(query, key, value):\n",
    "    softmax_sclae = 1.0\n",
    "    qs = torch.chunk(query, chunks=4, dim=2)\n",
    "    ks = torch.chunk(key, chunks=4, dim=2)\n",
    "    vs = torch.chunk(value, chunks=4, dim=2)\n",
    "    q = qs[0]\n",
    "    k = ks[0]\n",
    "    v = vs[0]\n",
    "    batch_size, num_heads, seqlen, head_dim = q.shape\n",
    "    qk = q @ k.transpose(-2, -1)\n",
    "    m_i = torch.max(qk, dim=-1, keepdim=True)[0]\n",
    "    p = torch.exp(qk - m_i)\n",
    "    l_ij = torch.sum(p, dim=-1, keepdim=True)\n",
    "    lse_i = torch.log(l_ij) + m_i\n",
    "    acc_o_scale = torch.exp(-m_i)\n",
    "    acc_o = p @ v\n",
    "    for i in range(3):\n",
    "        k = ks[i + 1]\n",
    "        v = vs[i + 1]\n",
    "        m_ij, l_ij, acc_o_scale, acc_o = update(q, k, v, m_i,acc_o, softmax_sclae)\n",
    "        m_i = m_ij\n",
    "        l_i_new = torch.exp(lse_i - m_ij) + l_ij\n",
    "        lse_i = m_ij + torch.log(l_i_new)\n",
    "    o_scale = torch.exp(m_i - lse_i)\n",
    "    acc_o = o_scale * acc_o\n",
    "    return acc_o\n",
    "\n",
    "    \n",
    "def ref_attn(q, k, v):\n",
    "    s = q @ k.transpose(-2, -1)\n",
    "    s = torch.softmax(s, dim=-1)\n",
    "    p = s @ v\n",
    "    return p\n",
    "\n",
    "batch = 2\n",
    "seqlen = 1024\n",
    "head_dim = 32\n",
    "num_heads = 16\n",
    "q = torch.randn((batch, num_heads, seqlen, head_dim),device=\"cuda\")\n",
    "k = torch.randn((batch, num_heads, seqlen, head_dim),device=\"cuda\")\n",
    "v = torch.randn((batch, num_heads, seqlen, head_dim),device=\"cuda\")\n",
    "p2 = ref_attn(q, k, v)\n",
    "# print(torch.allclose(p1, p2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from burst_attn_simple import OpBurstAttn\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 16, 256, 32])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 16, 256, 32])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_p2[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.1062e-06, device='cuda:0')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sub_p2[0] -p1).abs().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4493,  0.3916, -0.0198,  0.8010, -0.1278,  0.0292, -0.6342,  0.5712,\n",
       "        -0.1580, -0.3107, -0.3507,  0.4695, -0.2947, -0.1443, -0.2678, -0.1860,\n",
       "         0.0812,  0.0719,  0.1503,  0.2287, -0.4244,  0.9350,  0.3308, -0.5447,\n",
       "         1.1858, -0.1079, -1.1268, -0.5063, -0.4900,  0.0082, -0.0855, -0.4401],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1[0,0,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2 (default, Mar 25 2020, 17:03:02) \n[GCC 7.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f18e712d491a1263c2893900abe9bbe69048adb082d29e5c9c106bd8a7bd4b81"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
